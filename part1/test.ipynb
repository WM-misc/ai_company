{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b839de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 使用本地图片进行分析 ===\n",
      "本地图片分析失败: Error code: 400 - {'error': {'code': 'InvalidParameter.UnsupportedImageFormat', 'message': 'The request failed because the image format is not supported by the API. Request id: 021753091389724544488116183051b025229bd0a68274d77f0d9', 'param': 'image_url', 'type': 'BadRequest'}}\n",
      "本地图片分析示例已注释，请根据需要取消注释并修改图片路径\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_community.document_loaders.image import UnstructuredImageLoader\n",
    "\n",
    "OPENAI_API_KEY = \"6ef315b3-b065-483a-b1e4-7bbe1bc14d7f\"\n",
    "\n",
    "OPENAI_API_BASE = \"https://ark.cn-beijing.volces.com/api/v3\"\n",
    "OPENAI_API_MODEL = \"doubao-seed-1-6-250615\"\n",
    "\n",
    "llm = init_chat_model(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=OPENAI_API_BASE,\n",
    "    model=OPENAI_API_MODEL,\n",
    "    model_provider=\"openai\",\n",
    "    max_retries=3,\n",
    ")\n",
    "\n",
    "# LangChain 图像识别示例\n",
    "from langchain.schema import HumanMessage\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import mimetypes\n",
    "\n",
    "\n",
    "\n",
    "def get_image_mime_type(file_path):\n",
    "    \"\"\"获取图片的MIME类型\"\"\"\n",
    "    mime_type, _ = mimetypes.guess_type(file_path)\n",
    "    return mime_type or \"image/jpeg\"\n",
    "\n",
    "# 方法2: 使用本地图片文件（转换为base64）\n",
    "def analyze_local_image(image_path, text_prompt):\n",
    "    \"\"\"使用LangChain分析本地图片\"\"\"\n",
    "    # 读取图片并转换为base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    mime_type = get_image_mime_type(image_path)\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=[\n",
    "            {\n",
    "                \"type\": \"text\", \n",
    "                \"text\": text_prompt\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:{mime_type};base64,{base64_image}\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    thinking_config = {\n",
    "        \"thinking\": {\n",
    "            \"type\": \"enable\"  # 不使用深度思考能力\n",
    "        }\n",
    "    }\n",
    "    response = llm.invoke([message],config={\n",
    "        \"extra_body\": thinking_config\n",
    "    })\n",
    "    return response.content\n",
    "\n",
    "\n",
    "print(\"\\n=== 使用本地图片进行分析 ===\")\n",
    "try:\n",
    "    result2 = analyze_local_image(\n",
    "        \"./uploads/test_image.png\",\n",
    "        \"请分析这张图片的内容\"\n",
    "    )\n",
    "    print(f\"分析结果: {result2}\")\n",
    "except Exception as e:\n",
    "    print(f\"本地图片分析失败: {e}\")\n",
    "\n",
    "print(\"本地图片分析示例已注释，请根据需要取消注释并修改图片路径\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_company",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
